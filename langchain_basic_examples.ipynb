{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LanChain basic examples\n",
    "\"Get started\" examples of using LLMs with LangChain framework."
   ],
   "id": "60b3538d446ceb74"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-29T15:29:11.031238Z",
     "start_time": "2024-12-29T15:29:09.209487Z"
    }
   },
   "source": "!pip install openai",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/michal/anaconda3/lib/python3.12/site-packages (1.54.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from openai) (2.9.2)\r\n",
      "Requirement already satisfied: sniffio in /home/michal/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/michal/anaconda3/lib/python3.12/site-packages (from openai) (4.66.5)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/michal/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/michal/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/michal/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/michal/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T15:29:11.593627Z",
     "start_time": "2024-12-29T15:29:11.050495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ],
   "id": "5e5e38a0e28b7fc6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T15:29:11.666901Z",
     "start_time": "2024-12-29T15:29:11.644674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def chat(input):\n",
    "    messages = [{\"role\": \"user\", \"content\": input}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.1,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ],
   "id": "f24064a8fa4ea97b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T15:29:13.535677Z",
     "start_time": "2024-12-29T15:29:11.696893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"Who will fund salary rise for police, teachers, nurses, miners and firefighters?\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Try to answer question as politician\n",
    "Question: {question}\n",
    "\"\"\".format(\n",
    "    question=question\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "chat(prompt)"
   ],
   "id": "235b994c66231c22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Try to answer question as politician\n",
      "Question: Who will fund salary rise for police, teachers, nurses, miners and firefighters?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As a politician, it is my responsibility to ensure that essential workers such as police officers, teachers, nurses, miners, and firefighters are fairly compensated for their hard work and dedication. In order to fund salary increases for these important professions, we will need to carefully review our budget priorities and make strategic decisions on where to allocate resources. This may involve finding efficiencies in other areas, increasing revenue through taxes or other means, or seeking partnerships with private sector organizations. Ultimately, it is crucial that we prioritize the well-being and livelihoods of those who serve our communities every day.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Human message and AI message",
   "id": "d9062c1b83b803a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T15:29:15.027028Z",
     "start_time": "2024-12-29T15:29:13.585452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant! Your name is Janusz.\"),\n",
    "    SystemMessage(content=\"You like pizza with pineapple.\"),\n",
    "    HumanMessage(content=\"What is your name and what pizza do you recommend for today dinner?\"),\n",
    "]\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "print(model.predict_messages(messages))"
   ],
   "id": "7dbff1e3239c95a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47918/4000614462.py:11: LangChainDeprecationWarning: The method `BaseChatModel.predict_messages` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(model.predict_messages(messages))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! My name is Janusz. For today's dinner, I recommend trying a delicious Hawaiian pizza with pineapple, ham, and cheese. It's a classic combination that offers a perfect balance of sweet and savory flavors. Enjoy your meal!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 47, 'total_tokens': 96, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-283cbd7b-c7d5-48aa-bf8e-c572cc291c4a-0' usage_metadata={'input_tokens': 47, 'output_tokens': 49, 'total_tokens': 96, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wrapper classes for different LLMs",
   "id": "18733d868932e905"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T15:29:19.930276Z",
     "start_time": "2024-12-29T15:29:15.034987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install --upgrade --quiet langchain-anthropic\n",
    "!pip install --upgrade --quiet langchain-google-genai"
   ],
   "id": "e7343ebfe77bd324",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Antrophic Claude-3",
   "id": "e184110b1c508d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T15:29:24.491576Z",
     "start_time": "2024-12-29T15:29:19.938640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# add ANTROPHIC_API_KEY to .env to have access to Claude API\n",
    "model = ChatAnthropic(model='claude-3-opus-20240229')\n",
    "print(model.invoke(\"What is the area of Australia?\"))"
   ],
   "id": "aa38285e5904cba3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The area of Australia is approximately 7.692 million square kilometers (2.969 million square miles). This makes Australia the sixth-largest country in the world by total area, and the largest country in Oceania. The vast majority of Australia\\'s land area is on the mainland, with the island of Tasmania comprising about 68,000 square kilometers (26,000 square miles). Australia is often referred to as an \"island continent\" due to its size and the fact that it is surrounded by oceans.' additional_kwargs={} response_metadata={'id': 'msg_01Riy7bu933qunZi3aXx9rF8', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 14, 'output_tokens': 111}} id='run-3371c9b1-67d2-4552-bdcf-7ab646b3c8d7-0' usage_metadata={'input_tokens': 14, 'output_tokens': 111, 'total_tokens': 125, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Google Gemini",
   "id": "4a4f230b7e40e2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T15:29:26.926580Z",
     "start_time": "2024-12-29T15:29:24.577745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "# add GEMINI_API_KEY to .env to have access to Gemini API\n",
    "model = GoogleGenerativeAI(model=\"gemini-pro\")\n",
    "print(model.invoke(\"What is the area of Australia?\"))"
   ],
   "id": "c853808ddeb71aa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,741,220 sq km\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Deepinfra API: Mixtral, LLama 3.1",
   "id": "90ec37b87040d5f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.llms import DeepInfra\n",
    "import os\n",
    "\n",
    "os.environ[\"DEEPINFRA_API_TOKEN\"] = '<your DeepInfra API token>'\n",
    "\n",
    "# Create the DeepInfra instance. You can view a list of available parameters in the model page\n",
    "model = DeepInfra(model_id=\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "model = DeepInfra(model_id=\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
    "model.model_kwargs = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"max_new_tokens\": 250,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "print(model.invoke(\"What is the area of Australia?\"))"
   ],
   "id": "973052e3d085f1ae",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
