{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Example of using Llamaindex framework for Retrieval Augmented Generation\n",
    "This notebook shows how to run Llamaindex framework locally to create virtual AI assistant based on RAG (Retrieval Augmented Generation).\n",
    "For dataset to search for source information wikipedia articles about cryptocurrencies were used."
   ],
   "id": "70d30ca2d5a1c40"
  },
  {
   "cell_type": "markdown",
   "id": "1c909ec1-0a86-48a2-8411-f038788662d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Llamaindex setup\n",
    "### Download llamafile\n",
    "Download the llamafile with model. Llamafile can contain any LLM. Framework enabled to run it as a local server and use via API. \n",
    "TinyLlama-1.1B-Chat-v1.0 model is used for purpose of this example\n",
    "\n",
    "` wget https://huggingface.co/Mozilla/TinyLlama-1.1B-Chat-v1.0-llamafile/resolve/main/TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafile`\n",
    "\n",
    "Make executable \n",
    "\n",
    "`chmod +x TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafile`\n",
    "\n",
    "Run in server mode\n",
    "\n",
    "`./TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafile --server --nobrowser --embedding --port 8081`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Install Llamaindex Python library",
   "id": "134d68a367f51f2f"
  },
  {
   "cell_type": "code",
   "id": "0cb0a872-57d2-437b-ba7f-0dc5d47d02b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-07T18:18:47.353705Z",
     "start_time": "2024-12-07T18:18:18.773267Z"
    }
   },
   "source": [
    "# Install llama-index\n",
    "!pip install llama-index \n",
    "# Install llamafile integrations and SimpleWebPageReader\n",
    "!pip install llama-index-embeddings-llamafile llama-index-llms-llamafile llama-index-readers-web"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\r\n",
      "  Downloading llama_index-0.12.3-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\r\n",
      "  Downloading llama_index_agent_openai-0.4.0-py3-none-any.whl.metadata (726 bytes)\r\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\r\n",
      "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting llama-index-core<0.13.0,>=0.12.3 (from llama-index)\r\n",
      "  Downloading llama_index_core-0.12.3-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\r\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\r\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\r\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\r\n",
      "  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\r\n",
      "  Downloading llama_index_llms_openai-0.3.2-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting llama-index-multi-modal-llms-openai<0.4.0,>=0.3.0 (from llama-index)\r\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.3.0-py3-none-any.whl.metadata (726 bytes)\r\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\r\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\r\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\r\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\r\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\r\n",
      "  Downloading llama_index_readers_file-0.4.1-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\r\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index) (3.9.1)\r\n",
      "Requirement already satisfied: openai>=1.14.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.54.1)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/michal/anaconda3/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.4.54)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (3.10.5)\r\n",
      "Requirement already satisfied: dataclasses-json in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (0.6.7)\r\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13.0,>=0.12.3->llama-index)\r\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\r\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.3->llama-index)\r\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.3->llama-index)\r\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (2024.6.1)\r\n",
      "Requirement already satisfied: httpx in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (0.27.0)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (3.3)\r\n",
      "Requirement already satisfied: numpy in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (1.26.4)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (10.4.0)\r\n",
      "Collecting pydantic<2.10.0,>=2.7.0 (from llama-index-core<0.13.0,>=0.12.3->llama-index)\r\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (8.2.3)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (0.8.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (4.66.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (4.11.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (1.14.1)\r\n",
      "Collecting llama-cloud>=0.1.5 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\r\n",
      "  Downloading llama_cloud-0.1.6-py3-none-any.whl.metadata (814 bytes)\r\n",
      "Requirement already satisfied: pandas in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.5.3)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\r\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\r\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\r\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\r\n",
      "  Downloading llama_parse-0.5.17-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Requirement already satisfied: click in /home/michal/anaconda3/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /home/michal/anaconda3/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (2024.9.11)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (2.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.4.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.11.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/michal/anaconda3/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.5)\r\n",
      "Requirement already satisfied: anyio in /home/michal/anaconda3/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (4.2.0)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (2024.8.30)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/anaconda3/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.0.2)\r\n",
      "Requirement already satisfied: idna in /home/michal/anaconda3/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /home/michal/anaconda3/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.3.0)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/michal/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.3->llama-index) (0.14.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.7.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.3->llama-index) (0.6.0)\r\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.3->llama-index)\r\n",
      "  Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.3->llama-index) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.26.20)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/michal/anaconda3/lib/python3.12/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.3->llama-index) (3.0.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.3->llama-index) (3.23.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.3->llama-index) (24.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/michal/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.1->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\r\n",
      "Downloading llama_index-0.12.3-py3-none-any.whl (6.8 kB)\r\n",
      "Downloading llama_index_agent_openai-0.4.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\r\n",
      "Downloading llama_index_core-0.12.3-py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\r\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl (11 kB)\r\n",
      "Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m10.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading llama_index_llms_openai-0.3.2-py3-none-any.whl (13 kB)\r\n",
      "Downloading llama_index_multi_modal_llms_openai-0.3.0-py3-none-any.whl (5.9 kB)\r\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\r\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\r\n",
      "Downloading llama_index_readers_file-0.4.1-py3-none-any.whl (38 kB)\r\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\r\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\r\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\r\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\r\n",
      "Downloading llama_cloud-0.1.6-py3-none-any.whl (195 kB)\r\n",
      "Downloading llama_parse-0.5.17-py3-none-any.whl (14 kB)\r\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\r\n",
      "Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m10.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pypdf-5.1.0-py3-none-any.whl (297 kB)\r\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\r\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, pypdf, pydantic-core, deprecated, pydantic, llama-index-core, llama-cloud, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\r\n",
      "  Attempting uninstall: pydantic-core\r\n",
      "    Found existing installation: pydantic_core 2.20.1\r\n",
      "    Uninstalling pydantic_core-2.20.1:\r\n",
      "      Successfully uninstalled pydantic_core-2.20.1\r\n",
      "  Attempting uninstall: pydantic\r\n",
      "    Found existing installation: pydantic 1.10.19\r\n",
      "    Uninstalling pydantic-1.10.19:\r\n",
      "      Successfully uninstalled pydantic-1.10.19\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "fastapi 0.99.1 requires pydantic!=1.8,!=1.8.1,<2.0.0,>=1.7.4, but you have pydantic 2.9.2 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed deprecated-1.2.15 dirtyjson-1.0.8 filetype-1.2.0 llama-cloud-0.1.6 llama-index-0.12.3 llama-index-agent-openai-0.4.0 llama-index-cli-0.4.0 llama-index-core-0.12.3 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.3 llama-index-legacy-0.9.48.post4 llama-index-llms-openai-0.3.2 llama-index-multi-modal-llms-openai-0.3.0 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.1 llama-index-readers-llama-parse-0.4.0 llama-parse-0.5.17 pydantic-2.9.2 pydantic-core-2.23.4 pypdf-5.1.0 striprtf-0.0.26\r\n",
      "Collecting llama-index-embeddings-llamafile\r\n",
      "  Downloading llama_index_embeddings_llamafile-0.3.0-py3-none-any.whl.metadata (658 bytes)\r\n",
      "Collecting llama-index-llms-llamafile\r\n",
      "  Downloading llama_index_llms_llamafile-0.3.0-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting llama-index-readers-web\r\n",
      "  Downloading llama_index_readers_web-0.3.0-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-embeddings-llamafile) (0.12.3)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-readers-web) (3.10.5)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-readers-web) (4.12.3)\r\n",
      "Collecting chromedriver-autoinstaller<0.7.0,>=0.6.3 (from llama-index-readers-web)\r\n",
      "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting html2text<2025.0.0,>=2024.2.26 (from llama-index-readers-web)\r\n",
      "  Downloading html2text-2024.2.26.tar.gz (56 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting newspaper3k<0.3.0,>=0.2.8 (from llama-index-readers-web)\r\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web)\r\n",
      "  Downloading playwright-1.49.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-readers-web) (2.32.3)\r\n",
      "Collecting selenium<5.0.0,>=4.17.2 (from llama-index-readers-web)\r\n",
      "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Collecting spider-client<0.0.28,>=0.0.27 (from llama-index-readers-web)\r\n",
      "  Downloading spider-client-0.0.27.tar.gz (5.8 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: urllib3>=1.1.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-readers-web) (1.26.20)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (2.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.4.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.11.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/michal/anaconda3/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-web) (2.5)\r\n",
      "Requirement already satisfied: packaging>=23.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from chromedriver-autoinstaller<0.7.0,>=0.6.3->llama-index-readers-web) (24.1)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/michal/anaconda3/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (1.4.54)\r\n",
      "Requirement already satisfied: dataclasses-json in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (1.2.15)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (1.0.8)\r\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (1.2.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (2024.6.1)\r\n",
      "Requirement already satisfied: httpx in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (0.27.0)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (3.3)\r\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (3.9.1)\r\n",
      "Requirement already satisfied: numpy in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (1.26.4)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (10.4.0)\r\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (2.9.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (8.2.3)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (0.8.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (4.66.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (4.11.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /home/michal/anaconda3/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (1.14.1)\r\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /home/michal/anaconda3/lib/python3.12/site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (1.2.0)\r\n",
      "Requirement already satisfied: lxml>=3.6.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (5.2.1)\r\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\r\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (5.1.2)\r\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\r\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting jieba3k>=0.35.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\r\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.4/7.4 MB\u001B[0m \u001B[31m11.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (2.9.0.post0)\r\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\r\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting greenlet==3.1.1 (from playwright<2.0,>=1.30->llama-index-readers-web)\r\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\r\n",
      "Collecting pyee==12.0.0 (from playwright<2.0,>=1.30->llama-index-readers-web)\r\n",
      "  Downloading pyee-12.0.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web) (3.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web) (2024.8.30)\r\n",
      "Collecting trio~=0.17 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web)\r\n",
      "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web)\r\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Requirement already satisfied: websocket-client~=1.8 in /home/michal/anaconda3/lib/python3.12/site-packages (from selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.8.0)\r\n",
      "Requirement already satisfied: six in /home/michal/anaconda3/lib/python3.12/site-packages (from feedfinder2>=0.0.4->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (1.16.0)\r\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\r\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: click in /home/michal/anaconda3/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /home/michal/anaconda3/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (2024.9.11)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/michal/anaconda3/lib/python3.12/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (2.23.4)\r\n",
      "Requirement already satisfied: requests-file>=1.4 in /home/michal/anaconda3/lib/python3.12/site-packages (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (1.5.1)\r\n",
      "Requirement already satisfied: filelock>=3.0.8 in /home/michal/anaconda3/lib/python3.12/site-packages (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (3.13.1)\r\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web)\r\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: sortedcontainers in /home/michal/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (2.4.0)\r\n",
      "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\r\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.3.0)\r\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\r\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (1.0.0)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /home/michal/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.7.1)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (3.23.1)\r\n",
      "Requirement already satisfied: anyio in /home/michal/anaconda3/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (4.2.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/anaconda3/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (1.0.2)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/michal/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-llamafile) (0.14.0)\r\n",
      "Downloading llama_index_embeddings_llamafile-0.3.0-py3-none-any.whl (2.7 kB)\r\n",
      "Downloading llama_index_llms_llamafile-0.3.0-py3-none-any.whl (4.6 kB)\r\n",
      "Downloading llama_index_readers_web-0.3.0-py3-none-any.whl (76 kB)\r\n",
      "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\r\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\r\n",
      "Downloading playwright-1.49.0-py3-none-manylinux1_x86_64.whl (44.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.1/44.1 MB\u001B[0m \u001B[31m11.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading greenlet-3.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m613.1/613.1 kB\u001B[0m \u001B[31m9.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pyee-12.0.0-py3-none-any.whl (14 kB)\r\n",
      "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.7/9.7 MB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\r\n",
      "Downloading trio-0.27.0-py3-none-any.whl (481 kB)\r\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\r\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\r\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\r\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\r\n",
      "Building wheels for collected packages: html2text, tinysegmenter, spider-client, feedfinder2, jieba3k, sgmllib3k\r\n",
      "  Building wheel for html2text (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=f2cd0117d2b7f14029c08d62fb097d1f4647b7b34333be8fd97f35b1ac6c558a\r\n",
      "  Stored in directory: /home/michal/.cache/pip/wheels/2b/01/23/578505d65e2a97d78bf1fe3fc8256ecf37572dc1df598b0eaf\r\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13539 sha256=c9d9a0d22f37704e65c9632b333ee41e0443b3dac5f4bf1ef18befeb27639d60\r\n",
      "  Stored in directory: /home/michal/.cache/pip/wheels/a5/91/9f/00d66475960891a64867914273fcaf78df6cb04d905b104a2a\r\n",
      "  Building wheel for spider-client (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for spider-client: filename=spider_client-0.0.27-py3-none-any.whl size=5976 sha256=c38b338f93db4b34eaef851ee2bd653c6498bde359b1af5f9394bb8e951d8685\r\n",
      "  Stored in directory: /home/michal/.cache/pip/wheels/6c/41/42/4155300999390be7e455a6b05c602849f5810bf9383c43adb2\r\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3342 sha256=d8ca2937069e19247ed9880bdd11540c16395c07e7029ae53a6c7d99dad0148a\r\n",
      "  Stored in directory: /home/michal/.cache/pip/wheels/9f/9f/fb/364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\r\n",
      "  Building wheel for jieba3k (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398379 sha256=3757c6f526af8c1f82eb871de64d429bad7772156b462c02e008759e8470d218\r\n",
      "  Stored in directory: /home/michal/.cache/pip/wheels/26/72/f7/fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\r\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=9060d2426f8e1413aa6790fd9899848b8a0ac93f82a530c881d5a8ff33b91699\r\n",
      "  Stored in directory: /home/michal/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\r\n",
      "Successfully built html2text tinysegmenter spider-client feedfinder2 jieba3k sgmllib3k\r\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, wsproto, pyee, html2text, greenlet, feedparser, chromedriver-autoinstaller, attrs, spider-client, playwright, outcome, feedfinder2, trio, trio-websocket, newspaper3k, selenium, llama-index-llms-llamafile, llama-index-embeddings-llamafile, llama-index-readers-web\r\n",
      "  Attempting uninstall: greenlet\r\n",
      "    Found existing installation: greenlet 3.0.1\r\n",
      "    Uninstalling greenlet-3.0.1:\r\n",
      "      Successfully uninstalled greenlet-3.0.1\r\n",
      "  Attempting uninstall: attrs\r\n",
      "    Found existing installation: attrs 23.1.0\r\n",
      "    Uninstalling attrs-23.1.0:\r\n",
      "      Successfully uninstalled attrs-23.1.0\r\n",
      "Successfully installed attrs-24.2.0 chromedriver-autoinstaller-0.6.4 feedfinder2-0.0.4 feedparser-6.0.11 greenlet-3.1.1 html2text-2024.2.26 jieba3k-0.35.1 llama-index-embeddings-llamafile-0.3.0 llama-index-llms-llamafile-0.3.0 llama-index-readers-web-0.3.0 newspaper3k-0.2.8 outcome-1.3.0.post0 playwright-1.49.0 pyee-12.0.0 selenium-4.27.1 sgmllib3k-1.0.0 spider-client-0.0.27 tinysegmenter-0.3 trio-0.27.0 trio-websocket-0.11.1 wsproto-1.2.0\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "6f933ce6a118071d"
  },
  {
   "cell_type": "code",
   "id": "0bb2a20d-29a0-4d25-b9d4-f4e81db755fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-07T19:04:15.302029Z",
     "start_time": "2024-12-07T19:04:15.297847Z"
    }
   },
   "source": [
    "# Configure LlamaIndex\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.llamafile import LlamafileEmbedding\n",
    "from llama_index.llms.llamafile import Llamafile\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "#configure object to encode text into vector using started endpoint\n",
    "Settings.embed_model = LlamafileEmbedding(base_url=\"http://localhost:8081\")\n",
    "\n",
    "#configure object that will use model endpoint\n",
    "Settings.llm = Llamafile(\n",
    "    base_url=\"http://localhost:8081\",\n",
    "    temperature=0,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "#configure split text to chunks \n",
    "Settings.transformations = [\n",
    "    SentenceSplitter(\n",
    "        chunk_size=256, \n",
    "        chunk_overlap=5\n",
    "    )\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "39296b12-a3cb-4ed5-9d1a-68fab3954a31",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-07T19:04:17.808150Z",
     "start_time": "2024-12-07T19:04:17.800749Z"
    }
   },
   "source": [
    "# Load local data with some cryptocurrencies descriptions\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "# create reader for local documents\n",
    "local_doc_reader = SimpleDirectoryReader(input_dir='./data/cryptocurrency_wikipedia')\n",
    "# create collection that will contain all documents used for retrieval\n",
    "docs = local_doc_reader.load_data(show_progress=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading files: 100%|██████████| 3/3 [00:00<00:00, 2289.88file/s][A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\u001B[A\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "a4b84695-bce8-4875-a73f-cbb05b61a1ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-07T19:04:20.302341Z",
     "start_time": "2024-12-07T19:04:19.513434Z"
    }
   },
   "source": [
    "# Add Wikipedia pages\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "urls = [\n",
    "    'https://en.wikipedia.org/wiki/Bitcoin',\n",
    "    'https://en.wikipedia.org/wiki/Ethereum',\n",
    "    'https://en.wikipedia.org/wiki/Dogecoin'\n",
    "]\n",
    "# create reader that can fetch websites content\n",
    "web_reader = SimpleWebPageReader(html_to_text=True)\n",
    "# add fetched content to docs collection\n",
    "docs.extend(web_reader.load_data(urls))"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "b69bd884-bd9d-4a9e-8eab-ab75b4609460",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-07T19:04:21.600858Z",
     "start_time": "2024-12-07T19:04:20.885992Z"
    }
   },
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# create index storage with embedded documents\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    docs,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "# dump storage locally\n",
    "index.storage_context.persist(persist_dir=\"./storage\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parsing nodes:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b8e3cb0ea4b45bd8d7e7e0726fdbe55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating embeddings:   0%|          | 0/547 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea2af00cf7a1402d9b32023160d1035b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "HTTPStatusError",
     "evalue": "Server error '503 Service Unavailable' for url 'http://localhost:8081/embedding'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPStatusError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mllama_index\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VectorStoreIndex\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# create index storage with embedded documents\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m index \u001B[38;5;241m=\u001B[39m VectorStoreIndex\u001B[38;5;241m.\u001B[39mfrom_documents(\n\u001B[1;32m      5\u001B[0m     docs,\n\u001B[1;32m      6\u001B[0m     show_progress\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      7\u001B[0m )\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# dump storage locally\u001B[39;00m\n\u001B[1;32m     10\u001B[0m index\u001B[38;5;241m.\u001B[39mstorage_context\u001B[38;5;241m.\u001B[39mpersist(persist_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./storage\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/core/indices/base.py:119\u001B[0m, in \u001B[0;36mBaseIndex.from_documents\u001B[0;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m     docstore\u001B[38;5;241m.\u001B[39mset_document_hash(doc\u001B[38;5;241m.\u001B[39mget_doc_id(), doc\u001B[38;5;241m.\u001B[39mhash)\n\u001B[1;32m    112\u001B[0m nodes \u001B[38;5;241m=\u001B[39m run_transformations(\n\u001B[1;32m    113\u001B[0m     documents,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    114\u001B[0m     transformations,\n\u001B[1;32m    115\u001B[0m     show_progress\u001B[38;5;241m=\u001B[39mshow_progress,\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    117\u001B[0m )\n\u001B[0;32m--> 119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\n\u001B[1;32m    120\u001B[0m     nodes\u001B[38;5;241m=\u001B[39mnodes,\n\u001B[1;32m    121\u001B[0m     storage_context\u001B[38;5;241m=\u001B[39mstorage_context,\n\u001B[1;32m    122\u001B[0m     callback_manager\u001B[38;5;241m=\u001B[39mcallback_manager,\n\u001B[1;32m    123\u001B[0m     show_progress\u001B[38;5;241m=\u001B[39mshow_progress,\n\u001B[1;32m    124\u001B[0m     transformations\u001B[38;5;241m=\u001B[39mtransformations,\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    126\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:76\u001B[0m, in \u001B[0;36mVectorStoreIndex.__init__\u001B[0;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embed_model \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     70\u001B[0m     resolve_embed_model(embed_model, callback_manager\u001B[38;5;241m=\u001B[39mcallback_manager)\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m embed_model\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m Settings\u001B[38;5;241m.\u001B[39membed_model\n\u001B[1;32m     73\u001B[0m )\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insert_batch_size \u001B[38;5;241m=\u001B[39m insert_batch_size\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     77\u001B[0m     nodes\u001B[38;5;241m=\u001B[39mnodes,\n\u001B[1;32m     78\u001B[0m     index_struct\u001B[38;5;241m=\u001B[39mindex_struct,\n\u001B[1;32m     79\u001B[0m     storage_context\u001B[38;5;241m=\u001B[39mstorage_context,\n\u001B[1;32m     80\u001B[0m     show_progress\u001B[38;5;241m=\u001B[39mshow_progress,\n\u001B[1;32m     81\u001B[0m     objects\u001B[38;5;241m=\u001B[39mobjects,\n\u001B[1;32m     82\u001B[0m     callback_manager\u001B[38;5;241m=\u001B[39mcallback_manager,\n\u001B[1;32m     83\u001B[0m     transformations\u001B[38;5;241m=\u001B[39mtransformations,\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m     85\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/core/indices/base.py:77\u001B[0m, in \u001B[0;36mBaseIndex.__init__\u001B[0;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index_struct \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     76\u001B[0m     nodes \u001B[38;5;241m=\u001B[39m nodes \u001B[38;5;129;01mor\u001B[39;00m []\n\u001B[0;32m---> 77\u001B[0m     index_struct \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuild_index_from_nodes(\n\u001B[1;32m     78\u001B[0m         nodes \u001B[38;5;241m+\u001B[39m objects,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m     79\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m     80\u001B[0m     )\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_struct \u001B[38;5;241m=\u001B[39m index_struct\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_storage_context\u001B[38;5;241m.\u001B[39mindex_store\u001B[38;5;241m.\u001B[39madd_index_struct(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_struct)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:310\u001B[0m, in \u001B[0;36mVectorStoreIndex.build_index_from_nodes\u001B[0;34m(self, nodes, **insert_kwargs)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(content_nodes) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(nodes):\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSome nodes are missing content, skipping them...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 310\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_index_from_nodes(content_nodes, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minsert_kwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:279\u001B[0m, in \u001B[0;36mVectorStoreIndex._build_index_from_nodes\u001B[0;34m(self, nodes, **insert_kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m     run_async_tasks(tasks)\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 279\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_nodes_to_index(\n\u001B[1;32m    280\u001B[0m         index_struct,\n\u001B[1;32m    281\u001B[0m         nodes,\n\u001B[1;32m    282\u001B[0m         show_progress\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_show_progress,\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minsert_kwargs,\n\u001B[1;32m    284\u001B[0m     )\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m index_struct\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:232\u001B[0m, in \u001B[0;36mVectorStoreIndex._add_nodes_to_index\u001B[0;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001B[0m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m nodes_batch \u001B[38;5;129;01min\u001B[39;00m iter_batch(nodes, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insert_batch_size):\n\u001B[0;32m--> 232\u001B[0m     nodes_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_node_with_embedding(nodes_batch, show_progress)\n\u001B[1;32m    233\u001B[0m     new_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vector_store\u001B[38;5;241m.\u001B[39madd(nodes_batch, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minsert_kwargs)\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vector_store\u001B[38;5;241m.\u001B[39mstores_text \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_store_nodes_override:\n\u001B[1;32m    236\u001B[0m         \u001B[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001B[39;00m\n\u001B[1;32m    237\u001B[0m         \u001B[38;5;66;03m# we need to add the nodes to the index struct and document store\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:139\u001B[0m, in \u001B[0;36mVectorStoreIndex._get_node_with_embedding\u001B[0;34m(self, nodes, show_progress)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_node_with_embedding\u001B[39m(\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    129\u001B[0m     nodes: Sequence[BaseNode],\n\u001B[1;32m    130\u001B[0m     show_progress: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    131\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[BaseNode]:\n\u001B[1;32m    132\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;124;03m    Get tuples of id, node, and embedding.\u001B[39;00m\n\u001B[1;32m    134\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    137\u001B[0m \n\u001B[1;32m    138\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 139\u001B[0m     id_to_embed_map \u001B[38;5;241m=\u001B[39m embed_nodes(\n\u001B[1;32m    140\u001B[0m         nodes, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_embed_model, show_progress\u001B[38;5;241m=\u001B[39mshow_progress\n\u001B[1;32m    141\u001B[0m     )\n\u001B[1;32m    143\u001B[0m     results \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m nodes:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/core/indices/utils.py:148\u001B[0m, in \u001B[0;36membed_nodes\u001B[0;34m(nodes, embed_model, show_progress)\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    146\u001B[0m         id_to_embed_map[node\u001B[38;5;241m.\u001B[39mnode_id] \u001B[38;5;241m=\u001B[39m node\u001B[38;5;241m.\u001B[39membedding\n\u001B[0;32m--> 148\u001B[0m new_embeddings \u001B[38;5;241m=\u001B[39m embed_model\u001B[38;5;241m.\u001B[39mget_text_embedding_batch(\n\u001B[1;32m    149\u001B[0m     texts_to_embed, show_progress\u001B[38;5;241m=\u001B[39mshow_progress\n\u001B[1;32m    150\u001B[0m )\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m new_id, text_embedding \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(ids_to_embed, new_embeddings):\n\u001B[1;32m    153\u001B[0m     id_to_embed_map[new_id] \u001B[38;5;241m=\u001B[39m text_embedding\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001B[0m, in \u001B[0;36mDispatcher.span.<locals>.wrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    318\u001B[0m             _logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to reset active_span_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    320\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 321\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, asyncio\u001B[38;5;241m.\u001B[39mFuture):\n\u001B[1;32m    323\u001B[0m         \u001B[38;5;66;03m# If the result is a Future, wrap it\u001B[39;00m\n\u001B[1;32m    324\u001B[0m         new_future \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mensure_future(result)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/core/base/embeddings/base.py:335\u001B[0m, in \u001B[0;36mBaseEmbedding.get_text_embedding_batch\u001B[0;34m(self, texts, show_progress, **kwargs)\u001B[0m\n\u001B[1;32m    326\u001B[0m dispatcher\u001B[38;5;241m.\u001B[39mevent(\n\u001B[1;32m    327\u001B[0m     EmbeddingStartEvent(\n\u001B[1;32m    328\u001B[0m         model_dict\u001B[38;5;241m=\u001B[39mmodel_dict,\n\u001B[1;32m    329\u001B[0m     )\n\u001B[1;32m    330\u001B[0m )\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_manager\u001B[38;5;241m.\u001B[39mevent(\n\u001B[1;32m    332\u001B[0m     CBEventType\u001B[38;5;241m.\u001B[39mEMBEDDING,\n\u001B[1;32m    333\u001B[0m     payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mSERIALIZED: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_dict()},\n\u001B[1;32m    334\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m event:\n\u001B[0;32m--> 335\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_text_embeddings(cur_batch)\n\u001B[1;32m    336\u001B[0m     result_embeddings\u001B[38;5;241m.\u001B[39mextend(embeddings)\n\u001B[1;32m    337\u001B[0m     event\u001B[38;5;241m.\u001B[39mon_end(\n\u001B[1;32m    338\u001B[0m         payload\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m    339\u001B[0m             EventPayload\u001B[38;5;241m.\u001B[39mCHUNKS: cur_batch,\n\u001B[1;32m    340\u001B[0m             EventPayload\u001B[38;5;241m.\u001B[39mEMBEDDINGS: embeddings,\n\u001B[1;32m    341\u001B[0m         },\n\u001B[1;32m    342\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/llama_index/embeddings/llamafile/base.py:115\u001B[0m, in \u001B[0;36mLlamafileEmbedding._get_text_embeddings\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m    109\u001B[0m response \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mpost(\n\u001B[1;32m    110\u001B[0m     url\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/embedding\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    111\u001B[0m     headers\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapplication/json\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    112\u001B[0m     json\u001B[38;5;241m=\u001B[39mrequest_body,\n\u001B[1;32m    113\u001B[0m )\n\u001B[1;32m    114\u001B[0m response\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 115\u001B[0m response\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [output[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m response\u001B[38;5;241m.\u001B[39mjson()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_models.py:761\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    759\u001B[0m error_type \u001B[38;5;241m=\u001B[39m error_types\u001B[38;5;241m.\u001B[39mget(status_class, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid status code\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    760\u001B[0m message \u001B[38;5;241m=\u001B[39m message\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m, error_type\u001B[38;5;241m=\u001B[39merror_type)\n\u001B[0;32m--> 761\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m HTTPStatusError(message, request\u001B[38;5;241m=\u001B[39mrequest, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mHTTPStatusError\u001B[0m: Server error '503 Service Unavailable' for url 'http://localhost:8081/embedding'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T19:06:48.729217Z",
     "start_time": "2024-12-07T19:06:48.716683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create query type engine to ask questions to llm providing documents from index\n",
    "query_engine = index.as_query_engine()\n",
    "# ask questions about data from storage\n",
    "print(query_engine.query(\"What is Coinye?\"))"
   ],
   "id": "7f3a7fd326fcb070",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# create query type engine to ask questions to llm providing documents from index\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m query_engine \u001B[38;5;241m=\u001B[39m index\u001B[38;5;241m.\u001B[39mas_query_engine()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# ask questions about data from storage\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(query_engine\u001B[38;5;241m.\u001B[39mquery(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhat is Coinye?\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'index' is not defined"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T19:06:54.234938Z",
     "start_time": "2024-12-07T19:06:54.222885Z"
    }
   },
   "cell_type": "code",
   "source": "print(query_engine.query(\"Is Dogecoin stable?\"))",
   "id": "a6c9c97063254c4f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(query_engine\u001B[38;5;241m.\u001B[39mquery(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIs Dogecoin stable?\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'query_engine' is not defined"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T06:10:36.555409Z",
     "start_time": "2024-08-21T06:10:24.907264Z"
    }
   },
   "cell_type": "code",
   "source": "print(query_engine.query(\"Is Bitcoin good for environment?\"))",
   "id": "bf3b44d0ee7ad982",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Bitcoin is considered to be a good option for environment as it does not require any physical infrastructure, such as mining facilities, to operate. It is a decentralized and secure cryptocurrency that uses blockchain technology to verify transactions and maintain a decentralized ledger. This means that Bitcoin does not require any intermediaries or third-party entities to process transactions, which reduces the carbon footprint associated with traditional financial systems. Additionally, Bitcoin's energy consumption is significantly lower than that of traditional financial systems, making it a more sustainable option for the environment.</s>\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
