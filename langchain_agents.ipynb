{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Langchain Agents\n",
    "Agents use LLM to determine what actions to perform and in what order. Agents can use set of predefined tools to solve complex tasks."
   ],
   "id": "98fa5c210d9259f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T18:50:15.545886Z",
     "start_time": "2024-12-07T18:50:13.795952Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install arxiv",
   "id": "c433c14a5d91d8a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\r\n",
      "  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: feedparser~=6.0.10 in /home/michal/anaconda3/lib/python3.12/site-packages (from arxiv) (6.0.11)\r\n",
      "Requirement already satisfied: requests~=2.32.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from arxiv) (2.32.3)\r\n",
      "Requirement already satisfied: sgmllib3k in /home/michal/anaconda3/lib/python3.12/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (1.26.20)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (2024.8.30)\r\n",
      "Downloading arxiv-2.1.3-py3-none-any.whl (11 kB)\r\n",
      "Installing collected packages: arxiv\r\n",
      "Successfully installed arxiv-2.1.3\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-07T18:50:15.556595Z"
    }
   },
   "cell_type": "code",
   "source": [
    " from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import load_tools\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "tool_names = [\"arxiv\", \"llm-math\"] #archive with scientific papers\n",
    "tools = load_tools(tool_names, llm=llm)\n",
    "\n",
    "tool_list = [\n",
    "    Tool(\n",
    "        name=\"Arxiv\",\n",
    "        func=tools[0].run,\n",
    "        description=\"Search in scientific papers\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculation tool\",\n",
    "        func=tools[1].run,\n",
    "        description=\"Perform calculations\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(tool_list, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "agent.invoke(\"What the name of most famous scientific paper about text transformers? Could you process calculations mentioned in this paper to check if they are correct?\")"
   ],
   "id": "415cc5600d759503",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21198/3998349903.py:26: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  agent = initialize_agent(tool_list, llm, agent=\"zero-shot-react-description\", verbose=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mTo answer this question, I need to identify the most famous scientific paper about text transformers and then review the calculations mentioned in it. The most well-known paper in this field is likely \"Attention is All You Need\" by Vaswani et al., which introduced the Transformer model. I will first confirm this by searching for the paper.\n",
      "\n",
      "Action: Arxiv\n",
      "Action Input: \"Attention is All You Need\" by Vaswani et al.\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mNo good Arxiv Result was found\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mIt seems there was an issue retrieving the paper from Arxiv. However, I know that \"Attention is All You Need\" by Vaswani et al. is indeed the seminal paper that introduced the Transformer model, which is widely recognized in the field of natural language processing.\n",
      "\n",
      "To proceed with verifying the calculations mentioned in the paper, I will need to access the paper's content, particularly the sections that involve mathematical formulations or calculations. Since I cannot retrieve the paper directly from Arxiv, I will summarize the key calculations based on my knowledge.\n",
      "\n",
      "The paper introduces the Transformer model, which relies heavily on the self-attention mechanism. Key calculations involve:\n",
      "\n",
      "1. **Scaled Dot-Product Attention**: \n",
      "   \\[\n",
      "   \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
      "   \\]\n",
      "   where \\(Q\\), \\(K\\), and \\(V\\) are the query, key, and value matrices, and \\(d_k\\) is the dimension of the keys.\n",
      "\n",
      "2. **Multi-Head Attention**: \n",
      "   This involves linearly projecting the queries, keys, and values \\(h\\) times with different learned linear projections, performing the attention function in parallel, and then concatenating the results.\n",
      "\n",
      "3. **Position-wise Feed-Forward Networks**: \n",
      "   \\[\n",
      "   \\text{FFN}(x) = \\max(0, xW_1 + b_1)W_2 + b_2\n",
      "   \\]\n",
      "   where \\(W_1\\), \\(W_2\\), \\(b_1\\), and \\(b_2\\) are learned parameters.\n",
      "\n",
      "To verify these calculations, I will perform a simple check on the scaled dot-product attention formula using hypothetical values.\n",
      "\n",
      "Action: Calculation tool\n",
      "Action Input: {\n",
      "  \"Q\": [[1, 0], [0, 1]],\n",
      "  \"K\": [[1, 0], [0, 1]],\n",
      "  \"V\": [[1, 2], [3, 4]],\n",
      "  \"d_k\": 2\n",
      "}\u001B[0m"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T13:06:13.990644Z",
     "start_time": "2024-09-13T13:06:13.985596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.agent_toolkits.load_tools import get_all_tool_names\n",
    "print(get_all_tool_names())"
   ],
   "id": "5d2e9401e331383",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sleep', 'wolfram-alpha', 'google-search', 'google-search-results-json', 'searx-search-results-json', 'bing-search', 'metaphor-search', 'ddg-search', 'google-lens', 'google-serper', 'google-scholar', 'google-finance', 'google-trends', 'google-jobs', 'google-serper-results-json', 'searchapi', 'searchapi-results-json', 'serpapi', 'dalle-image-generator', 'twilio', 'searx-search', 'merriam-webster', 'wikipedia', 'arxiv', 'golden-query', 'pubmed', 'human', 'awslambda', 'stackexchange', 'sceneXplain', 'graphql', 'openweathermap-api', 'dataforseo-api-search', 'dataforseo-api-search-json', 'eleven_labs_text2speech', 'google_cloud_texttospeech', 'read_file', 'reddit_search', 'news-api', 'tmdb-api', 'podcast-api', 'memorize', 'llm-math', 'open-meteo-api', 'requests', 'requests_get', 'requests_post', 'requests_patch', 'requests_put', 'requests_delete', 'terminal']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Custom Tool",
   "id": "bc50f06b1a4d6d5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T13:40:06.085770Z",
     "start_time": "2024-09-13T13:40:02.222114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "from langchain.agents import AgentType\n",
    "import nltk\n",
    "\n",
    "# download NLTK data packages\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')\n",
    "\n",
    "class CustomNERTool(BaseTool):\n",
    "    name = \"NER tagger\"\n",
    "    description = \"named entity recognition tagger\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        tokens = nltk.word_tokenize(query)\n",
    "        tagged_tokens = nltk.pos_tag(tokens)\n",
    "        return nltk.ne_chunk(tagged_tokens)\n",
    "\n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"not suppored\")\n",
    "\n",
    "tools = [CustomNERTool()]\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "agent.run(\"Tag NER text: John Doe is a founder of ExampleCorp that was created in 1986 in Australia.\") "
   ],
   "id": "4445850ddb110a5b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/michal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/michal/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/michal/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to /home/michal/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mI need to identify the named entities in the given text using the NER tagger.\n",
      "Action: NER tagger\n",
      "Action Input: John Doe is a founder of ExampleCOrp that was created in 1986 in Australia.\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m(S\n",
      "  (PERSON John/NNP)\n",
      "  (ORGANIZATION Doe/NNP)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  founder/NN\n",
      "  of/IN\n",
      "  (ORGANIZATION ExampleCOrp/NNP)\n",
      "  that/WDT\n",
      "  was/VBD\n",
      "  created/VBN\n",
      "  in/IN\n",
      "  1986/CD\n",
      "  in/IN\n",
      "  (GPE Australia/NNP)\n",
      "  ./.)\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The named entities in the text are:\n",
      "- PERSON: John\n",
      "- ORGANIZATION: Doe, ExampleCOrp\n",
      "- GPE (Geopolitical Entity): Australia\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The named entities in the text are:\\n- PERSON: John\\n- ORGANIZATION: Doe, ExampleCOrp\\n- GPE (Geopolitical Entity): Australia'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Evaluating Agents\n",
    "solving tasks with agents can be evaluated by Trajectory Evaluator, which checks if agent resoning is going right path  \n",
    "see: https://js.langchain.com/v0.1/docs/guides/evaluation/trajectory/trajectory_eval/"
   ],
   "id": "2ed017738240e425"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
