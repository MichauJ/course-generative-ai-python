{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transformers library use case types\n",
    "Common examples of using transformers library with models from huggingface.co."
   ],
   "id": "7628049b1250bae2"
  },
  {
   "cell_type": "code",
   "id": "44508dfc-47c4-4a3e-9a11-f99f4fb0490d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T08:25:04.722883Z",
     "start_time": "2024-11-10T08:24:57.560893Z"
    }
   },
   "source": [
    "!pip install transformers\n",
    "!pip install tensorflow\n",
    "!pip install tf-keras\n",
    "!pip install sacremoses\n",
    "!pip install torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/michal/anaconda3/lib/python3.12/site-packages (4.46.2)\r\n",
      "Requirement already satisfied: filelock in /home/michal/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/michal/anaconda3/lib/python3.12/site-packages (from transformers) (0.26.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/michal/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/michal/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\r\n",
      "Requirement already satisfied: requests in /home/michal/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\r\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/michal/anaconda3/lib/python3.12/site-packages (from transformers) (0.20.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/michal/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\r\n",
      "Requirement already satisfied: tensorflow in /home/michal/anaconda3/lib/python3.12/site-packages (2.18.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.25.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (75.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.67.1)\r\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.18.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.6.0)\r\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.4.1)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\r\n",
      "Requirement already satisfied: rich in /home/michal/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /home/michal/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /home/michal/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\r\n",
      "Requirement already satisfied: tf-keras in /home/michal/anaconda3/lib/python3.12/site-packages (2.18.0)\r\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /home/michal/anaconda3/lib/python3.12/site-packages (from tf-keras) (2.18.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.25.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.11.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.14.1)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.67.1)\r\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.6.0)\r\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.11.0)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\r\n",
      "Requirement already satisfied: rich in /home/michal/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /home/michal/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /home/michal/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/michal/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (2.1.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.15.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.0)\r\n",
      "Requirement already satisfied: sacremoses in /home/michal/anaconda3/lib/python3.12/site-packages (0.1.1)\r\n",
      "Requirement already satisfied: regex in /home/michal/anaconda3/lib/python3.12/site-packages (from sacremoses) (2024.9.11)\r\n",
      "Requirement already satisfied: click in /home/michal/anaconda3/lib/python3.12/site-packages (from sacremoses) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /home/michal/anaconda3/lib/python3.12/site-packages (from sacremoses) (1.4.2)\r\n",
      "Requirement already satisfied: tqdm in /home/michal/anaconda3/lib/python3.12/site-packages (from sacremoses) (4.66.5)\r\n",
      "Requirement already satisfied: torch in /home/michal/anaconda3/lib/python3.12/site-packages (2.5.1)\r\n",
      "Requirement already satisfied: filelock in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\r\n",
      "Requirement already satisfied: networkx in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.1.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (3.1.0)\r\n",
      "Requirement already satisfied: setuptools in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/michal/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/michal/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\r\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "3eb54b97-b0e3-4a24-a907-48a8778dbbfe",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "id": "45e033c3-383b-4896-94e2-fb39ca81f6c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T08:25:05.054733Z",
     "start_time": "2024-11-10T08:25:04.730121Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead, pipeline\n",
    "\n",
    "def download_model(model_name: str, pipe_type='text-generation'):\n",
    "   tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "   model = AutoModelWithLMHead.from_pretrained(model_name)\n",
    "   pipe = pipeline(pipe_type, model=model, tokenizer=tokenizer)\n",
    "   return pipe\n",
    "\n",
    "\n",
    "text = \"Provide recipe with list of steps to cook cheesecake.\"\n",
    "pipe = download_model(\"gpt2\")\n",
    "text_generated = pipe(text, max_new_tokens=200,temperature=0.01)\n",
    "\n",
    "print(text_generated[0]['generated_text'])"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelWithLMHead requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelWithLMHead\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 11\u001B[0m\n\u001B[1;32m      7\u001B[0m    \u001B[38;5;28;01mreturn\u001B[39;00m pipe\n\u001B[1;32m     10\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProvide recipe with list of steps to cook cheesecake.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 11\u001B[0m pipe \u001B[38;5;241m=\u001B[39m download_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt2\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m text_generated \u001B[38;5;241m=\u001B[39m pipe(text, max_new_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m,temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(text_generated[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "Cell \u001B[0;32mIn[10], line 5\u001B[0m, in \u001B[0;36mdownload_model\u001B[0;34m(model_name, pipe_type)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdownload_model\u001B[39m(model_name: \u001B[38;5;28mstr\u001B[39m, pipe_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext-generation\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m      4\u001B[0m    tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n\u001B[0;32m----> 5\u001B[0m    model \u001B[38;5;241m=\u001B[39m AutoModelWithLMHead\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n\u001B[1;32m      6\u001B[0m    pipe \u001B[38;5;241m=\u001B[39m pipeline(pipe_type, model\u001B[38;5;241m=\u001B[39mmodel, tokenizer\u001B[38;5;241m=\u001B[39mtokenizer)\n\u001B[1;32m      7\u001B[0m    \u001B[38;5;28;01mreturn\u001B[39;00m pipe\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1651\u001B[0m, in \u001B[0;36mDummyObject.__getattribute__\u001B[0;34m(cls, key)\u001B[0m\n\u001B[1;32m   1649\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_from_config\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1650\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(key)\n\u001B[0;32m-> 1651\u001B[0m requires_backends(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_backends)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1630\u001B[0m, in \u001B[0;36mrequires_backends\u001B[0;34m(obj, backends)\u001B[0m\n\u001B[1;32m   1628\u001B[0m \u001B[38;5;66;03m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001B[39;00m\n\u001B[1;32m   1629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m backends \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m backends \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_available() \u001B[38;5;129;01mand\u001B[39;00m is_tf_available():\n\u001B[0;32m-> 1630\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001B[38;5;241m.\u001B[39mformat(name))\n\u001B[1;32m   1632\u001B[0m \u001B[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001B[39;00m\n\u001B[1;32m   1633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m backends \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m backends \u001B[38;5;129;01mand\u001B[39;00m is_torch_available() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tf_available():\n",
      "\u001B[0;31mImportError\u001B[0m: \nAutoModelWithLMHead requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelWithLMHead\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "d75a3c63-9a94-433e-8617-46eb67a198d2",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d1673c1-841d-4d5f-bc5b-26a8d8a42cf7",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-10T08:25:16.503120Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Załaduj model klasyfikacji tekstów\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Przykładowe artykuły\n",
    "articles = [\n",
    "    \"The government announced new tax reforms today.\",\n",
    "    \"The local team won the championship in a thrilling match.\",\n",
    "    \"New advancements in AI are reshaping the tech industry.\",\n",
    "    \"The art exhibit showcased contemporary works by emerging artists.\",\n",
    "    \"New guidelines for a healthy diet were published by the health department.\"\n",
    "]\n",
    "\n",
    "# Definiowanie możliwych kategorii\n",
    "candidate_labels = [\"Polityka\", \"Sport\", \"Technologia\", \"Kultura\", \"Zdrowie\"]\n",
    "\n",
    "# Klasyfikacja artykułów\n",
    "results = classifier(articles, candidate_labels=candidate_labels)\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "for article, result in zip(articles, results):\n",
    "    print(f\"Article: {article}\")\n",
    "    print(f\"Predicted Category: {result['labels'][0]}, Confidence: {result['scores'][0]}\\n\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aab96ce398b6458b9a50b8841b4f5d3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e36d7abbc4948379fa67da89ec35139"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "048dcf8e-e246-4bab-bf49-0a2637722e08",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5937a6ce-2c2f-413b-9965-fd26b48ea123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1ce0d3c3bc42c5b22e422fc103896b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7319c16117741aca80e26d5275ac6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ffec19dd87432290e666082ae620cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a52e79a91b640a193726482a9f1fae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec31174161649d1bcaf9a467dc6f975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This product is amazing! I loved it.\n",
      "Sentiment: positive, Confidence: 0.9866390228271484\n",
      "\n",
      "Review: I am very disappointed. The product broke after one use.\n",
      "Sentiment: negative, Confidence: 0.930964469909668\n",
      "\n",
      "Review: It's okay, does the job but nothing special.\n",
      "Sentiment: neutral, Confidence: 0.6142873764038086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Załaduj model klasyfikacji sentymentu (może to być np. model GPT lub inny dostępny w ramach transformers)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "# Przykładowe recenzje\n",
    "reviews = [\n",
    "    \"This product is amazing! I loved it.\",\n",
    "    \"I am very disappointed. The product broke after one use.\",\n",
    "    \"It's okay, does the job but nothing special.\"\n",
    "]\n",
    "\n",
    "# Klasyfikacja recenzji\n",
    "results = classifier(reviews)\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "for review, result in zip(reviews, results):\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Sentiment: {result['label']}, Confidence: {result['score']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b4b4e3-4f4a-46f2-8a00-21d5ca5e3c3d",
   "metadata": {},
   "source": [
    "## Document analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0824601-ebaa-4076-9960-908f9acdc921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410a2c61fa344bf7acaf8e18a838434f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForQuestionAnswering were not initialized from the model checkpoint at google/flan-t5-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.0001070289799827151, 'start': 10720, 'end': 10760, 'answer': ' <td style=\"text-align:right;\">45,3</td>'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"question-answering\", model=\"google/flan-t5-base\")\n",
    "\n",
    "file = open(\"data/annual_report.html\", \"r\")\n",
    "document = file.read()\n",
    "result = pipe(question=\"What is annual revenue of the company based on attached annual report?\", context=document )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b660b8-7bcb-4ca6-bc2b-11a6f257f292",
   "metadata": {},
   "source": [
    "## Machine translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fca90d40-1524-4a85-a955-3f812e620f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FSMTForConditionalGeneration were not initialized from the model checkpoint at facebook/wmt19-en-de and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Ich bin Ausländer und spreche kein fließend Deutsch.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"translation\", model=\"facebook/wmt19-en-de\")\n",
    "\n",
    "result = pipe(\"I'm foreigner and I don't speak german fluently.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c066a83-65fb-41d9-8962-b2bd9495c1af",
   "metadata": {},
   "source": [
    "## Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa8dfd1f-1de7-45b8-9056-8934f5dd05b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.2113601565361023, 'start': 19, 'end': 40, 'answer': 'z siedzibą w Poznaniu'}, {'score': 0.09133698046207428, 'start': 350, 'end': 373, 'answer': 'Marketing i technologie'}, {'score': 0.00805636402219534, 'start': 1058, 'end': 1062, 'answer': '1996'}, {'score': 0.0014388621784746647, 'start': 50, 'end': 82, 'answer': 'uczelnia niepubliczna w Poznaniu'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "result = pipe(context=\"\"\"Collegium Da Vinci z siedzibą w Poznaniu – polska uczelnia niepubliczna w Poznaniu. Collegium Da Vinci to praktyczna uczelnia biznesowa kształcąca specjalistów w obszarze kreatywnego sektora biznesu. W ofercie posiada studia dyplomowe (I i II stopnia) i podyplomowe (w tym EMBA) w 4 głównych obszarach: Media kreatywne i sztuka, IT i analiza danych, Marketing i technologie, Zarządzanie i HR.\n",
    "Uczelnia realizuje model nauczania oparty na diagnozie indywidualnych predyspozycji studentów (test Gallupa, Insightful Profiler™), indywidualizacji ścieżek kształcenia (moduły dodatkowe) oraz wsparciu tutorów w wyznaczaniu i osiąganiu edukacyjnych celów.\n",
    "Oferowane przez CDV kierunki są mocno osadzone w realiach rynkowych, są tworzone wspólnie z biznesem oraz zorientowane na naukę praktycznych umiejętności zawodowych, aby pomagać studentom i słuchaczom w zaprojektowaniu lub rozwoju ich kariery zawodowej. Collegium Da Vinci kształci w podejściu interdyscyplinarnym, łącząc biznes z kreatywnością i humanistycznym podejściem do technologii.\n",
    "Historia\n",
    "10 czerwca 1996 Minister Edukacji Narodowej udzielił zezwolenia na utworzenie Wyższej Szkoły Nauk Humanistycznych i Dziennikarstwa w Poznaniu, której pomysłodawcą oraz założycielem jest Piotr Voelkel. WSNHiD zostało wpisane do wykazu uczelni niepublicznych pod numerem 90. W tym samym roku pierwsi studenci rozpoczęli kształcenie na kierunku politologia i nauki społeczne. Dwa lata później na WSNHiD powstaje nowy kierunek – stosunki międzynarodowe. W 2000 uruchomione zostają kolejne kierunki – socjologia i kulturoznawstwo, a w roku następnym – informatyka. W 2006 uczelnia uzyskuje zgodę na kształcenie na kierunku pedagogika. \"\"\",\n",
    "      question=['What is Collegium da Vinci?',\n",
    "'What are services of Collegium da Vinci?',\n",
    "'When Collegium Da Vinci was founded?',\n",
    "'Where are headquarters of Collegium da Vinci?'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c5c6e-7904-4b10-aabe-0480ab29e975",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e6b83d-a125-4a58-9aa4-9f86380fb521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Dzień był letni i świąteczny. Ciepło i radość lały się z błękitnego nieba i złotego słońca.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "file = open(\"data/nad_niemnem.txt\", \"r\")\n",
    "document = file.read()\n",
    "result = pipe(document[:800], max_length=100, min_length=20, do_sample=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247af2a0-5321-404c-9849-212ad552ee26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
