{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LangChain Chains\n",
    "\n",
    "Chaining LLM tasks helps building advanced AI applications that can handle a sequence of tasks or resoning.  "
   ],
   "id": "37df4435dc3fccd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T09:10:45.600054Z",
     "start_time": "2024-12-08T09:10:44.741659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ],
   "id": "7b1413f7c92c7552",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T18:36:14.006390Z",
     "start_time": "2024-12-07T18:36:12.672497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = \"\"\"\n",
    "Extract name of a person and language of message from the input.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "name\n",
    "language\n",
    "\n",
    "text: {input}\n",
    "\"\"\"\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "name_lang_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "name_lang_chain.predict(input=\"Herr Josef Braun ist am 22.09.1999 geboren.\")"
   ],
   "id": "abce6e8506642746",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19021/1338294985.py:11: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0)\n",
      "/tmp/ipykernel_19021/1338294985.py:13: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  name_lang_chain = LLMChain(llm=llm, prompt=prompt_template)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n{\\n    \"name\": \"Josef Braun\",\\n    \"language\": \"German\"\\n}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sequential Chain",
   "id": "3d9a89da70d2befb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T18:37:00.790246Z",
     "start_time": "2024-12-07T18:36:58.129122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_template = \"\"\"\n",
    "You are an AI assistant generating greeting message for the beginning of an e-mail. \n",
    "Propose greeting using provided name and language.\n",
    "\n",
    "text: {input}\n",
    "\"\"\"\n",
    "greeting_template = PromptTemplate(input_variables=[\"input\"], template=response_template)\n",
    "greeting_chain = LLMChain(llm=llm, prompt=greeting_template)\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[name_lang_chain, greeting_chain], verbose=True)\n",
    "\n",
    "overall_chain.run(input=\"Herr Josef Braun ist am 22.09.1999 geboren.\")"
   ],
   "id": "53e31a735548ba37",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19021/2838309493.py:13: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  overall_chain.run(input=\"Herr Josef Braun ist am 22.09.1999 geboren.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m\n",
      "{\n",
      "    \"name\": \"Josef Braun\",\n",
      "    \"language\": \"German\"\n",
      "}\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m\n",
      "Guten Tag Josef Braun,\n",
      "\n",
      "Ich hoffe, es geht Ihnen gut. Ich wollte Ihnen nur eine kurze E-Mail schreiben, um mich vorzustellen und Ihnen mitzuteilen, dass ich Ihr neuer AI-Assistent bin. Ich freue mich darauf, Ihnen bei all Ihren Aufgaben und Anfragen behilflich zu sein. Zögern Sie nicht, mich jederzeit zu kontaktieren.\n",
      "\n",
      "Mit freundlichen Grüßen,\n",
      "[Your Name]\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGuten Tag Josef Braun,\\n\\nIch hoffe, es geht Ihnen gut. Ich wollte Ihnen nur eine kurze E-Mail schreiben, um mich vorzustellen und Ihnen mitzuteilen, dass ich Ihr neuer AI-Assistent bin. Ich freue mich darauf, Ihnen bei all Ihren Aufgaben und Anfragen behilflich zu sein. Zögern Sie nicht, mich jederzeit zu kontaktieren.\\n\\nMit freundlichen Grüßen,\\n[Your Name]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Custom callback",
   "id": "63a361321c507fbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T18:40:15.864237Z",
     "start_time": "2024-12-07T18:40:14.431207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class CustomHandler(BaseCallbackHandler):\n",
    "    buffer = []\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.buffer.append(token)\n",
    "        if len(self.buffer) == 4:\n",
    "            self.buffer.reverse() # inverse order of words to make text like said by master Yoda\n",
    "            print(' '.join(self.buffer))\n",
    "            self.buffer = []\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\"Answer a question{question}\"])\n",
    "model = ChatOpenAI(streaming=True, callbacks=[CustomHandler()])\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\"question\": \"What is the path of Jedi?\"})"
   ],
   "id": "ac0bd2c00622488",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of  path The \n",
      " to  is  Jedi  a\n",
      " of  teachings  the  follow\n",
      ",  Order  Jedi  the\n",
      " knowledge  seeking  includes  which\n",
      ",  peace  maintaining ,\n",
      " and ,  justice  defending\n",
      " for  Force  the  using\n",
      ".  good  greater  the\n",
      " to  strive  also  Jedi\n",
      " themselves  within  balance  maintain\n",
      ",  universe  the  and\n",
      "ations  tempt  the  resist\n",
      " side  dark  the  of\n",
      " the  uphold  and ,\n",
      ",  compassion  of  principles\n",
      " and , lessness  self\n",
      ". ipline -disc  self\n",
      " of  goal  ultimate  The\n",
      " to  is  Jedi  a\n",
      " the  with  one  become\n",
      " a  achieve  and  Force\n",
      " and  harmony  of  state\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6fdfbd7a8df871db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
